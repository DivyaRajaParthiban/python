from __future__ import print_function
import sys
from pyspark.sql import Row
from pyspark.sql import SparkSession
from pyspark import SparkConf
from pyspark.sql import SparkSession, HiveContext
from pyspark.sql.types import *
from pyspark.sql.functions import explode
from pyspark import SparkContext
from pyspark.streaming import StreamingContext
from pyspark.streaming.kafka import KafkaUtils

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: direct_kafka_stream.py <broker_list> <topic>", file=sys.stderr)
        exit(-1)
    #spark = SparkSession.builder.getOrCreate()
    spark = SparkSession.builder.enableHiveSupport().getOrCreate()
    print("\n\n\n CHAT PROJECT \n")
    #Define the column names as id,chat,type
    udschema = StructType([StructField("ID",StringType(), True),
    StructField("CHAT",StringType(), True),
    StructField("TYPE",StringType(), True)])

    sc = spark.sparkContext
    ssc = StreamingContext(sc, 60)

    brokers, topic = sys.argv[1:]
    kvs = KafkaUtils.createDirectStream(ssc, [topic], {"metadata.broker.list": brokers})
    lines = kvs.map(lambda x: x[1])
    lines2 = lines.map(lambda l: l.split("~"))
    chatlinetypec = lines2.filter(lambda l: l[2].upper() == 'C')
    chatlinetypec.foreachRDD(lambda rdd: chat(rdd) )
        #DF = spark.createDataFrame(chatlinetypec,udschema)
    #DF.show()
    chatlinetypec.pprint()

    def chat(rdd):
      DF = spark.createDataFrame(rdd,udschema)
      DF.show()
      DF1 = DF.drop('TYPE')
      DF1.createOrReplaceTempView("ChatTempView")
      chat_split =spark.sql("SELECT ID, split(CHAT,' ') AS SPCHAT from ChatTempView")
      chat_split.show()
      Exp_chat_split_DF = chat_split.select(chat_split.ID, explode(chat_split.SPCHAT))
      Exp_chat_split_DF.createOrReplaceTempView("ExpChatTempView")
      ECTP = spark.sql("SELECT * FROM ExpChatTempView")
      ECTP.show()
      swschema = StructType([StructField("STOPWORD",StringType(), True)])
      stopwordDF = spark.read.load("file:/home/hduser/Stopwords.csv",format="csv",header="False",schema=swschema)
      stopwordDF.createOrReplaceTempView("StopwordView")
      SWDF = spark.sql("SELECT * FROM StopwordView")
      #SWDF.show()
      CleanChat = spark.sql("SELECT * FROM ExpChatTempView where col NOT IN (SELECT * FROM StopwordView)")
      CleanChat.show()
      spark.sql("use default")
      spark.sql("drop table if exists Finalchat")
      spark.sql("create table if not exists Finalchat AS SELECT * FROM ExpChatTempView where col NOT IN (SELECT * FROM StopwordView)")
      spark.sql("SELECT * FROM Finalchat").show()
      spark.sql("SELECT count(id), col FROM Finalchat GROUP BY col").show()
      
    ssc.start()
    ssc.awaitTermination()
